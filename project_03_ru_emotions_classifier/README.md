# RuGoEmotions: Multi-label Emotion Classification

Проект по разработке модели для распознавания эмоций в текстах на русском языке. Основан на англоязычном датасете **GoEmotions**, переведенном на русский язык, и легковесной модели **RuBERT-tiny2**.

## Описание задачи
Необходимо классифицировать текст по 28 категориям эмоций (например, *admiration, joy, sadness, anger, neutral*). Данный текст переводен на русский с помощью opus-mt-en-ru. Особенность задачи — **Multi-label classification** (один текст может содержать несколько эмоций одновременно) и сильный дисбаланс классов.

## Почему это важно
Не всегда есть датасет на нужном языке, так как большинство данных на английском языке, и было бы полезно, в случае нехватки данных на русском  языке, автоматически переводить данные с английского языка на русский и затем передавать их модель.
А классификация эмоции текста способна понять, например, тон клиента в чате поддержки для того, чтобы в случае негативной реакции быстро поменять оператора.

## Проблемы
Основной проблемой являлся сильный дисбаланс классов: между максимальный класс больше минимального почти в 185 раз.


## Технический стек
* **Язык:** Python
* **DL Фреймворк:** PyTorch
* **NLP:** Hugging Face Transformers (Trainer API)
* **Модели:** `Helsinki-NLP/opus-mt-en-ru` (для перевода), `cointegrated/rubert-tiny2` (для классификации)
* **Метрики:** F1-Score (Macro)

## Этапы реализации
1.  **Подготовка данных:**
    * Загрузка датасета GoEmotions.
    * Машинный перевод текстов с английского на русский (pipeline `translation`).
    * Преобразование меток в формат Multi-hot encoding.

2.  **Обучение:**
    * Использование предобученной модели `rubert-tiny2`.
    * Реализация кастомного **Weighted BCEWithLogitsLoss** для учета дисбаланса классов (редкие эмоции получают больший вес).
    * Обучение с использованием `Trainer`.

3.  **Оптимизация:**
    * Подбор индивидуальных порогов уверенности (thresholds) для каждого из 28 классов на валидационной выборке позволил повысить метрику F1-Macro.
    
4.  **Аналитика:**
    * Построение матрицы корреляций предсказанных эмоций (какие эмоции модель часто видит вместе).

## Файлы проекта
- [emotions_classifier_notebook.ipynb](https://github.com/AgapovKS/pet_projects/blob/main/project_03_ru_emotions_classifier/emotions_classifier_notebook.ipynb): Код с графиками и обучением модели
- [model_weights](https://github.com/AgapovKS/pet_projects/tree/main/project_03_ru_emotions_classifier/model_weights): Сохраненная модель со всеми пороговыми значениями

## Результаты
* Модель выучила зависимости между текстом и эмоциями, что было показно на придуманных примерах
* **Прирост качества:** Использование индивидуальных порогов (вместо стандартного 0.5) дало прирост метрики F1-Macro (с ~0.39 до ~0.42), что является неплохим результатом при таком большом дисбалансе 
* Модель сохранена и готова к будущему инференсу.
  
### Визуализации результатов
* Матрица корреляций предсказанных эмоций
<img width="1280" height="1198" alt="image" src="https://github.com/user-attachments/assets/e390ce4b-0946-4944-ace5-96e1e6466aa6" />
* Анализ сильных и слабых результатов
<img width="989" height="790" alt="image" src="https://github.com/user-attachments/assets/23e94748-8355-4518-975e-1211c8d3ba25" />

## Пример работы
**Вход:** "Спасибо большое, мне это помогло"
**Предсказание:** `gratitude` (97.5%)

**Вход:** "Я чувствую себя подавленным"
**Предсказание:** `sadness` (80.6%)
